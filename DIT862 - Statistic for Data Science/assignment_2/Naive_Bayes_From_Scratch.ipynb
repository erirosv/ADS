{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2gUALxIPBws"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anoXZlS6Tj8x"
   },
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIRT9JX5A3g3"
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tfYRcVtA5bS"
   },
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "\n",
    "  if isinstance(test_size, float):\n",
    "    test_size = round(test_size*len(df))\n",
    "  \n",
    "  indices = df.index.tolist() # random.sample takes list, set, dictionary\n",
    "  test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "  test = df.loc[test_indices]\n",
    "  train = df.drop(test_indices)\n",
    "\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rW28gtRhXGxT"
   },
   "source": [
    "## Calculate Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4hlvd5nV44e"
   },
   "outputs": [],
   "source": [
    "def calculate_prior_probabilities(df):\n",
    "    prior_probabilities = df.groupby(by = 'target').apply(lambda x: len(x)/len(df))\n",
    "    return np.log(prior_probabilities).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42ONfI_tkg-J"
   },
   "outputs": [],
   "source": [
    "# calculate_prior_probabilities(df)\n",
    "\n",
    "# [Prior_probability(setosa), Prior_probability(versicolor), Prior_probability(virginica)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCVsNsy-ZC3c"
   },
   "source": [
    "## Find mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhBDIS0JZCav"
   },
   "outputs": [],
   "source": [
    "def return_statistics(df):\n",
    "    mean = df.groupby(by='target').apply(lambda x: x.mean(axis=0))\n",
    "    variance = df.groupby(by='target').apply(lambda x: x.var(axis=0))\n",
    "    return (mean.values, variance.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z91Ei4T-fwZn"
   },
   "outputs": [],
   "source": [
    "# mean, variance = return_statistics(df)\n",
    "# print(mean)\n",
    "# print(variance)\n",
    "\n",
    "#             s_l  s_w  p_l  p_w\n",
    "# setosa\n",
    "# versicolor\n",
    "# virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWXFmsvcXY9v"
   },
   "source": [
    "## Find Gaussian Probability density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qnu1CIs-XB6-"
   },
   "outputs": [],
   "source": [
    "# P(x=12 | 'setosa')\n",
    "\n",
    "def calculate_probability_density(mean, variance, x):\n",
    "    probability_density = (1 / np.sqrt(2*np.pi*variance) ) * np.exp( (-(x - mean)**2)  / ( 2*variance ) )\n",
    "    return probability_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lgh-OaJ_05Ln"
   },
   "source": [
    "## Posterior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ueSjXpbX-3r"
   },
   "outputs": [],
   "source": [
    "def calculate_posterior_probabilities(df_row, mean, variance, n_unique_labels, n_cols):\n",
    "  \n",
    "  posterior_probabilities = []\n",
    "  \n",
    "  # calculate probabilities wrt each label to find max\n",
    "    for i in range(n_unique_labels):\n",
    "        posterior = 0\n",
    "\n",
    "    # for each feature\n",
    "    for j in range(n_cols):\n",
    "        posterior += np.log(calculate_probability_density(mean[i][j], variance[i][j], df_row[j]))\n",
    "    posterior_probabilities.append(posterior)\n",
    "  \n",
    "  return posterior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loqxsXX1X-yB"
   },
   "outputs": [],
   "source": [
    "# calculate_posterior_probabilities()\n",
    "\n",
    "# [posterior_probability['setosa'], posterior_probability['versicolor'], posterior_probability['virginica']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6LKgZzh00jz"
   },
   "source": [
    "## Fit model on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ma7rUVppX-vt"
   },
   "outputs": [],
   "source": [
    "def NBA_fit(df):\n",
    "    n_cols = len(df.columns)-1\n",
    "    unique_labels = df['target'].unique()\n",
    "    n_unique_labels = len(unique_labels)\n",
    "\n",
    "    mean, variance = return_statistics(df)\n",
    "    prior_probabilities = calculate_prior_probabilities(df) # returns log\n",
    "\n",
    "    return {\n",
    "      'n_cols': n_cols,\n",
    "      'unique_labels': unique_labels,\n",
    "      'n_unique_labels': n_unique_labels,\n",
    "      'mean': mean,\n",
    "      'variance': variance,\n",
    "      'prior_probabilities': prior_probabilities\n",
    "    }\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xz3fxWBiX-tL"
   },
   "outputs": [],
   "source": [
    "# nba = NBA_fit(df)\n",
    "\n",
    "# Returns a dictonary containing statistical and other important info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM6GHJtb0yFz"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UFBuSjbxiOI"
   },
   "outputs": [],
   "source": [
    "def predict(test_df, nba):\n",
    "    predictions = []\n",
    "    for i in range(len(test_df)):\n",
    "\n",
    "    prior = nba['prior_probabilities']\n",
    "    posterior = calculate_posterior_probabilities(test_df.iloc[i, :-1], nba['mean'], nba['variance'], nba['n_unique_labels'], nba['n_cols'])  # returns log\n",
    "    probabilities = prior + posterior\n",
    "    # one with max prob will be the output \n",
    "    mx_idx = np.argmax(probabilities)\n",
    "\n",
    "    predictions.append(nba['unique_labels'][mx_idx])  # add log values\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLZrR1joX-rG"
   },
   "outputs": [],
   "source": [
    "# predictions = predict(test_df, nba)\n",
    "\n",
    "# returns label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clVNrTLV809l"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "IEjVfRkhTO_v",
    "outputId": "ab0e92a0-f7af-49cd-bbeb-a0c45da02bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 135,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('iris')\n",
    "df_copy = df.copy()\n",
    "df.rename(columns={'species': 'target'}, inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYAcCD9xIa6P"
   },
   "source": [
    "No null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzcWouD5AZoX",
    "outputId": "c28acbf3-5797-4d45-cf8c-4f7ccf1f1954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "train_df, test_df = train_test_split(df, 0.2)\n",
    "\n",
    "# fit model\n",
    "nba = NBA_fit(train_df)\n",
    "\n",
    "# make predictions\n",
    "predictions = predict(test_df, nba)\n",
    "\n",
    "# accuracy\n",
    "accuracy = len(test_df.loc[predictions == test_df['target']])/len(test_df) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-fzSmYcnH1p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sv_IDmtnHzV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_Bayes_From_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
