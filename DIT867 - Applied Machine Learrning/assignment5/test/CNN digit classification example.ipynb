{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying handwritten digits using convolutional neural networks\n",
    "\n",
    "In this example, we will apply convolutional neural networks (CNNs) to MNIST, a dataset containing images of handwritten digits. This is one of the most well-known datasets in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we initialize the random number generator before loading Keras, we'll get the same\n",
    "# result each time we run the notebook.\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To set the color used to display monochrome images.\n",
    "plt.rcParams['image.cmap'] = 'Blues'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and preprocessing the data\n",
    "\n",
    "Keras includes a function to load the MNIST data. The function returns two pairs: the input and output data of the training and test set, respectively.\n",
    "\n",
    "These are all 28x28 grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_width, img_height = x_train[0].shape\n",
    "\n",
    "img_width, img_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can apply the CNN, we need to carry out a few steps of preprocessing.\n",
    "\n",
    "First, we need to reshape the data a bit into a form that is suitable for the CNN. Currently, each image is represented as a 28x28 matrix. Even though the images are in a grayscale format, we need to convert them to three-dimensional objects (formally, 3-dimensional *tensors*). The reason is that all convolutions in Keras are applied to 3-dimensional data, even for grayscale images.\n",
    "\n",
    "This means that the whole training set and test set become four-dimensional. (Number of images x 28 x 28 x 1.)\n",
    "\n",
    "We use NumPy's `reshape` operation to carry out this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_width, img_height, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second transformation is a rescaling of the pixel values. Instead of ranging from 0 to 255, they will now be in the range between 0 and 1.\n",
    "\n",
    "The reason for this transformation is just that it is easier for the CNN to learn if the features values aren't too large. (Alternatively, we could have initialized the CNN weights to smaller values.) If you don't rescale, the CNN will still learn, just more slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To exemplify, let's use `plt.imshow` to visualize an image. (This function assumes that the pixel values are between 0 and 1, so the rescaling we did above is necessary here as well.)\n",
    "\n",
    "The notation `x_train[12,:,:,0]` means: 12th image in training set, all rows and columns, and first color dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[12,:,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**OPTIONALLY**, as a final step of preprocessing, we can convert the output labels (digits) into \"one-hot\" vectors. For instance, the digit 2 will become `[0,0,1,0,...,0]`. In older versions of Keras, this was necessary when using the softmax output layer and the categorical cross-entropy loss function. In modern Keras versions, we can use the `sparse_categorical_crossentropy` loss function to keep things simpler, and this preprocessing can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = keras.utils.to_categorical(y_train)\n",
    "#y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# For instance, here is how the first instance in the training set is encodes.\n",
    "#y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training the CNN\n",
    "\n",
    "Now we have everything to train the CNN. As in the feedforward NN, we start by creating a `Sequential` model. (This means that our classifier consists of layers.)\n",
    "\n",
    "Then, we alternate convolutional and pooling layers, as is customary in CNN. We use ReLU units in the hidden layers. Finally, we apply a `Flatten`, to convert the feature maps after the last pooling step into vectors. The final part of the model looks like a normal feedforward neural network: first, a standard hidden layer using 128 units, and finally the output softmax layer.\n",
    "\n",
    "We train the model using the Adam optimizer. To keep things simple, we let it train for just one epoch; for real-world problems, there would be many epochs, probably using early stopping to determine when to terminate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 28s 119ms/step - loss: 0.2743 - accuracy: 0.9226 - val_loss: 0.0791 - val_accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_width, img_height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that if you retrain the model, the result might be a slightly different, because of randomness in weight initialization and in the Adam optimizer.\n",
    "\n",
    "We can evaluate as we did in the previous notebook, using `predict_class` and scikit-learn's `accuracy_score`, but we can also take a shortcut by calling `model.evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0791323184967041\n",
      "Test accuracy: 0.9764999747276306\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the output\n",
    "\n",
    "Let's exemplify the classifier's output.\n",
    "\n",
    "We first take a look at an instance from the test set. Let's say for instance that we look at the 100th instance (which happens to represent the number 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[100,:,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the predictions for all instances in the test set. We do this in two steps: first, we compute the probabilities predicted by the classifier using the softmax output for all instances in the test set. This gives us a $N$ x 10 matrix, where $N$ is the number of instances and 10 because there are 10 possible digits (from 0 to 9). Secondly, for each row (test set instance), we find the digit that has the highest probability.\n",
    "\n",
    "As you can see, the model has made a correct prediction for the 100th instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probs = model.predict(x_test)\n",
    "\n",
    "guesses = predicted_probs.argmax(axis=-1)\n",
    "\n",
    "guesses[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a small helper function that sorts the probabilities and prints them in the sorted order.\n",
    "\n",
    "Again considering the 100th instance, we see that it has been determined to be an image of the digit 6 with a probability very close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: 0.9972\n",
      "0: 0.0015\n",
      "8: 0.0007\n",
      "5: 0.0003\n",
      "4: 0.0001\n",
      "2: 0.0001\n",
      "1: 0.0000\n",
      "9: 0.0000\n",
      "3: 0.0000\n",
      "7: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def print_probs(ps):\n",
    "    for p, i in sorted([(p, i) for i, p in enumerate(ps)], reverse=True):\n",
    "        print(f'{i}: {p:.4f}')\n",
    "\n",
    "print_probs(predicted_probs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's inspect some of the errors.\n",
    "\n",
    "We gather all misclassified instances in a list. For each misclassified instance, we store the output probability of the guessed class, the probabilities of all classes, the true digit class, and the image.\n",
    "\n",
    "We sort the list by the output probabilities, so that the first instances in the list are those where the classifier had a (misguided) high confidence in the erroneous predictions.\n",
    "\n",
    "As you can see, 187 out of the 10,000 test instances were misclassified. [Again, this number may vary if you retrain the model, because of randomness in the training process.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "for x, y, g, p in zip(x_test, y_test, guesses, predicted_probs):    \n",
    "    if y != g:\n",
    "        errors.append( (p[g], p, y, x[:,:,0]) )\n",
    "\n",
    "errors.sort(reverse=True)\n",
    "\n",
    "len(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the instance where the classifier was most confident in its incorrect prediction. In this case, this is an instance of the digit 6, which was misclassified as a 4. This instance is quite hard to classify even for the human eye.\n",
    "\n",
    "[Again, you may see a different result if you retrain.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label: 6\n",
      "0: 0.9990\n",
      "6: 0.0009\n",
      "9: 0.0000\n",
      "5: 0.0000\n",
      "2: 0.0000\n",
      "8: 0.0000\n",
      "3: 0.0000\n",
      "4: 0.0000\n",
      "7: 0.0000\n",
      "1: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_error(err):\n",
    "    _, p, label, img = err    \n",
    "    print('Correct label:', label)\n",
    "    print_probs(p)\n",
    "    plt.imshow(img)\n",
    "        \n",
    "show_error(errors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
