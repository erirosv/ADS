{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-94d7fc18-f8e5-4a33-8c56-07e11f3363ca",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Task 3: Feature importances in random forest classifiers\n",
    "Decision trees and random forests are trained by computing importance scores for individual features in different ways: information gain, Gini impurity, variance reduction, etc.\n",
    "\n",
    "As a way to make our classifiers more interpretable, we can print the importance scores. In scikit-learn, decision trees and ensemble classifiers such as random forests all define an attribute called feature_importances_ (note the final underscore in this name). This is a NumPy array that stores the importance scores for each feature column in the training data matrix. For random forests and other tree ensembles, these importance scores are computed by averaging the scores when training all the different trees in the ensemble.\n",
    "\n",
    "To make these importance scores easier to understand, we can use the attribute feature_names_ (note the underscore again) in the DictVectorizer.\n",
    "\n",
    "Sort the features by importance scores in reverse order (so that the most important feature comes first), inspect the first few of these features, and try to reason about why you got this result.\n",
    "\n",
    "Hint. If you used a Pipeline, you can access the parts of the sequence via the list pipeline.steps. For instance, pipeline.steps[0][1] will be the first step, pipeline.steps[1][1] will be the second step, etc.\n",
    "\n",
    "Hint. This way of computing feature importance scores just tells us whether a feature is good for discriminating between the classes: it does not tell us what the relationship between the feature and an output class is: whether the feature makes it more or less likely that the person is a high earner.\n",
    "\n",
    "For your report, please also mention an alternative way to compute some sort of importance score of individual features. (You don't need to implement it.) Here, you can either use your common sense, or optionally read the discussion by Parr et al. (2018) that gives some criticism of decision tree-based feature importance scores and discusses some alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-9fac0ce8-b401-4523-b88f-7afe0c7d2b3c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1933,
    "execution_start": 1643294061042,
    "source_hash": "1408a858",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-b676809a-3c64-4e88-a97c-86a16de8df82",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1454,
    "execution_start": 1643294064644,
    "source_hash": "8b4d470a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import csv file for Training data\n",
    "train = pd.read_csv('adult_train.csv')\n",
    "\n",
    "# Import csv file for Test data\n",
    "test = pd.read_csv('adult_test.csv')\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "# convert X data to dict - creates a list of dicts \n",
    "# where each row's (person's) information is gathered in one dict, \n",
    "Xtrain_dicts = train.drop('target', axis=1).to_dict('records')\n",
    "Xtest_dicts = test.drop('target', axis=1).to_dict('records')\n",
    "Ytrain = train['target']\n",
    "Ytest = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-4b393b98-22ac-4500-ad02-55c14ac9c319",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1643296240695,
    "source_hash": "161c3447",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAKE PIPELINE\n",
    "pipeline = Pipeline(steps=[('dv', DictVectorizer()), ('rfc', RandomForestClassifier())])\n",
    "\n",
    "# Specify params to search\n",
    "hparams_grid = {'rfc__max_depth':  [1,3,6,9,12,15,18,21,51],\n",
    "                'rfc__n_estimators': [1,3,6,9,12,15,21,26,51,76,101,126,151,176,201,226,251] }\n",
    "\n",
    "# Random search since faster\n",
    "random_search = RandomizedSearchCV(pipeline, hparams_grid, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c9cfa123-76dd-4531-9cfc-6d791c8e4d22",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     1
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 128,
    "execution_start": 1643294290617,
    "source_hash": "e6d43624",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__dictvectorizer', 'estimator__randomforestclassifier', 'estimator__dictvectorizer__dtype', 'estimator__dictvectorizer__separator', 'estimator__dictvectorizer__sort', 'estimator__dictvectorizer__sparse', 'estimator__randomforestclassifier__bootstrap', 'estimator__randomforestclassifier__ccp_alpha', 'estimator__randomforestclassifier__class_weight', 'estimator__randomforestclassifier__criterion', 'estimator__randomforestclassifier__max_depth', 'estimator__randomforestclassifier__max_features', 'estimator__randomforestclassifier__max_leaf_nodes', 'estimator__randomforestclassifier__max_samples', 'estimator__randomforestclassifier__min_impurity_decrease', 'estimator__randomforestclassifier__min_samples_leaf', 'estimator__randomforestclassifier__min_samples_split', 'estimator__randomforestclassifier__min_weight_fraction_leaf', 'estimator__randomforestclassifier__n_estimators', 'estimator__randomforestclassifier__n_jobs', 'estimator__randomforestclassifier__oob_score', 'estimator__randomforestclassifier__random_state', 'estimator__randomforestclassifier__verbose', 'estimator__randomforestclassifier__warm_start', 'estimator', 'n_iter', 'n_jobs', 'param_distributions', 'pre_dispatch', 'random_state', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check available params\n",
    "random_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-b287540c-76c6-49c5-bdd1-f3626c2a361d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     607
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 62042,
    "execution_start": 1643296241590,
    "source_hash": "a41e2739",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 62.00542140007019\n"
     ]
    }
   ],
   "source": [
    "# time it\n",
    "start = time.time()\n",
    "# train\n",
    "random_search.fit(Xtrain_dicts, Ytrain)\n",
    "end = time.time()\n",
    "time_grid_train = end - start\n",
    "print('Train time: {}'.format(time_grid_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-1f5b2395-a6ac-43da-9e11-dfb2787d2b03",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1643296416448,
    "source_hash": "c515194d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8625349612625062\n",
      "Best params: {'rfc__n_estimators': 51, 'rfc__max_depth': 21}\n"
     ]
    }
   ],
   "source": [
    "# store best params\n",
    "r_best_m_d = random_search.best_params_['rfc__max_depth']\n",
    "r_best_n_e = random_search.best_params_['rfc__n_estimators']\n",
    "\n",
    "# print result\n",
    "print(\"Best Score: {}\".format(random_search.best_score_))\n",
    "print(\"Best params: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b2979fab-bc5c-45d9-ab4b-02c554a6db74",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     1
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 410,
    "execution_start": 1643296456054,
    "source_hash": "af5d9716",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615564154535962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy on unseen test data\n",
    "accuracy_score(Ytest, random_search.predict(Xtest_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5ec9ffb5-8828-4dc0-8f70-6b3cff3d38e0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7097,
    "execution_start": 1643297416256,
    "source_hash": "6b34b8a5",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b170e3abe903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "random_search.named_steps[\"dv\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-f35a1e18-49a0-42c6-b2e7-22fd56190f4b",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     520.0625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1643297477100,
    "source_hash": "14044861",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DictVectorizer' object has no attribute 'feature_names_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-bfc66a41beae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the names of each feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the impurity-based feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrfc_feature_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"randomforestclassifier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/feature_extraction/_dict_vectorizer.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m            \u001b[0mList\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f=ham\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"f=spam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DictVectorizer' object has no attribute 'feature_names_'"
     ]
    }
   ],
   "source": [
    "# Get the names of each feature\n",
    "feature_names = pipeline.named_steps[\"dv\"].get_feature_names()\n",
    "\n",
    "# Get the impurity-based feature importances\n",
    "rfc_feature_score = pipeline.named_steps[\"randomforestclassifier\"].feature_importances_\n",
    "\n",
    "# print top 10 result\n",
    "for s, f in sorted(zip(rfc_feature_score, feature_names), reverse=True)[:10]:\n",
    "    print(f, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-d4e62506-b8b9-467c-94c7-dd112eef373d",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     520.0625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1643290525661,
    "source_hash": "97b951ac",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital-status=Married-civ-spouse 8025.8420615949835\n",
      "relationship=Husband 6240.018276214241\n",
      "education-num 4120.095779707474\n",
      "marital-status=Never-married 3674.2001465697413\n",
      "age 1886.7073137161203\n",
      "hours-per-week 1813.3862822161334\n",
      "relationship=Own-child 1794.1574893573925\n",
      "capital-gain 1709.150063743795\n",
      "sex=Female 1593.1079074467164\n",
      "sex=Male 1593.1079074467073\n"
     ]
    }
   ],
   "source": [
    "# Get the Scores of features\n",
    "scores = pipeline.named_steps[\"selectkbest\"].scores_\n",
    "\n",
    "for s, f in sorted(zip(scores, feature_names), reverse=True)[:10]:\n",
    "    print(f, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-fccd54f0-064f-4aa4-9129-a0f1e83c66f5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 52,
    "execution_start": 1643290317829,
    "source_hash": "29248653",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital-status=Married-civ-spouse 8025.8420615949835\n",
      "relationship=Husband 6240.018276214241\n",
      "education-num 4120.095779707474\n",
      "marital-status=Never-married 3674.2001465697413\n",
      "age 1886.7073137161203\n",
      "hours-per-week 1813.3862822161334\n",
      "relationship=Own-child 1794.1574893573925\n",
      "capital-gain 1709.150063743795\n",
      "sex=Female 1593.1079074467164\n",
      "sex=Male 1593.1079074467073\n"
     ]
    }
   ],
   "source": [
    "# feature selection with f_classif\n",
    "feature_scores1 = f_classif(Xtrain_encoded, Ytrain)[0]\n",
    "\n",
    "# print result\n",
    "for score, fname in sorted(zip(feature_scores1, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-4a664ca9-e317-4ace-a13d-0af2123b1f10",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4290,
    "execution_start": 1643290283677,
    "source_hash": "897f8ebf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital-status=Married-civ-spouse 0.10543223425355985\n",
      "capital-gain 0.08338237212343601\n",
      "relationship=Husband 0.08087684110742101\n",
      "age 0.0687725396789363\n",
      "education-num 0.064872227626807\n",
      "marital-status=Never-married 0.06195072410418583\n",
      "hours-per-week 0.0422833222022355\n",
      "relationship=Own-child 0.03821610420273137\n",
      "capital-loss 0.03698048451035268\n",
      "sex=Male 0.025765242400373284\n"
     ]
    }
   ],
   "source": [
    "# feature selection with mutual info classif\n",
    "feature_scores2 = mutual_info_classif(Xtrain_encoded, Ytrain)\n",
    "\n",
    "# print result\n",
    "for score, fname in sorted(zip(feature_scores2, dv.get_feature_names_out()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-20f44267-997e-4ea1-bf7b-85d32a0e562b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##### Comments:\n",
    "**Reason about why you got these first few features as top features:**\n",
    "\n",
    "The top features listed when using mutual_info_classif and f_classif were the below computed as the mean decrease in impurity. The importance score indicate that these features are most predictive of earnings:\n",
    "1. Maritial status (=Married), \n",
    "2. Capital Gain\n",
    "3. Relationship status (=Husband), \n",
    "4. Age\n",
    "\n",
    "Maritial status and relationship may be a strong indicator of your earnings in such a way that prioritising time with the family. Generally we can argue that age results in higher salary growing with your role and career. However, as stated these do not indicate wheather the income was above or below the 50k. \n",
    "\n",
    "**For your report, please also mention an alternative way to compute some sort of importance score of individual features. (You don't need to implement it.) Here, you can either use your common sense, or optionally read the discussion by Parr et al. (2018) that gives some criticism of decision tree-based feature importance scores and discusses some alternatives.**\n",
    "\n",
    "Other than the above tested scikitlearn's built in feature importance scores one can use permutation based importance score described by Parr et al (2018). \n",
    "\n",
    "The importance score is the difference between the baseline accuracy and accuracy by permutin the column values. It is hevaier to compute but more reliable as less biased. \n",
    "\n",
    "---\n",
    "The most common mechanism to compute feature importances, and the one used in scikit-learn's RandomForestClassifier and RandomForestRegressor, is the mean decrease in impurity (or gini importance) mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-1b4de02b-83c9-432c-bb46-882a4927d083",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6da6a8e6-0c44-46dd-834b-4f197b47408c",
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
