{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8365a796-ef15-454f-b52a-e7cec116635b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1643288169462,
    "source_hash": "3fffb081",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Authors: Andreas Nilsson, Anouka Ranby, Erik Rosvall (All part of ADS program)\n",
    "# Date: 23 Jan 2022\n",
    "# Description: Decision Trees - Applied Machine Learning, DIT867\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7bbd278e-09f3-47d3-a4c3-71cea917dc80",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Task 3: Feature importances in random forest classifiers\n",
    "Decision trees and random forests are trained by computing importance scores for individual features in different ways: information gain, Gini impurity, variance reduction, etc.\n",
    "\n",
    "As a way to make our classifiers more interpretable, we can print the importance scores. In scikit-learn, decision trees and ensemble classifiers such as random forests all define an attribute called feature_importances_ (note the final underscore in this name). This is a NumPy array that stores the importance scores for each feature column in the training data matrix. For random forests and other tree ensembles, these importance scores are computed by averaging the scores when training all the different trees in the ensemble.\n",
    "\n",
    "To make these importance scores easier to understand, we can use the attribute feature_names_ (note the underscore again) in the DictVectorizer.\n",
    "\n",
    "Sort the features by importance scores in reverse order (so that the most important feature comes first), inspect the first few of these features, and try to reason about why you got this result.\n",
    "\n",
    "Hint. If you used a Pipeline, you can access the parts of the sequence via the list pipeline.steps. For instance, pipeline.steps[0][1] will be the first step, pipeline.steps[1][1] will be the second step, etc.\n",
    "\n",
    "Hint. This way of computing feature importance scores just tells us whether a feature is good for discriminating between the classes: it does not tell us what the relationship between the feature and an output class is: whether the feature makes it more or less likely that the person is a high earner.\n",
    "\n",
    "For your report, please also mention an alternative way to compute some sort of importance score of individual features. (You don't need to implement it.) Here, you can either use your common sense, or optionally read the discussion by Parr et al. (2018) that gives some criticism of decision tree-based feature importance scores and discusses some alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "76af6108-e323-48f8-af27-d6474c831bae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1643360366634,
    "source_hash": "3614a264",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "57f815df-b0f1-489e-a712-5b6b8da9c161",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 737,
    "execution_start": 1643360255248,
    "source_hash": "8b4d470a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import csv file for Training data\n",
    "train = pd.read_csv('adult_train.csv')\n",
    "\n",
    "# Import csv file for Test data\n",
    "test = pd.read_csv('adult_test.csv')\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "# convert X data to dict - creates a list of dicts \n",
    "# where each row's (person's) information is gathered in one dict, \n",
    "Xtrain_dicts = train.drop('target', axis=1).to_dict('records')\n",
    "Xtest_dicts = test.drop('target', axis=1).to_dict('records')\n",
    "Ytrain = train['target']\n",
    "Ytest = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "73b52ccc-5647-4e54-8184-86ae20f98bf0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 642,
    "execution_start": 1643360260096,
    "source_hash": "47a91bf5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create d DictVectorizer \n",
    "dv = DictVectorizer()\n",
    "\n",
    "# one-hot encode the list with all dicts\n",
    "Xtrain_encoded = dv.fit_transform(Xtrain_dicts)\n",
    "Xtest_encoded = dv.transform(Xtest_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "169d8a83-76f1-48c9-a6db-8d3120477653",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1643360261849,
    "source_hash": "aa1e14ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Find good hyperparameters for Random Forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# specify grid\n",
    "hparams_grid = {'max_depth':  [1,3,6,9,12,15,18,21,51],\n",
    "                'n_estimators': [1,3,6,9,12,15,21,26,51,76,101,126,151,176,201,226,251] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3bfac680-ced8-4fd9-955c-1b78de9785f6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 100319,
    "execution_start": 1643360266319,
    "source_hash": "560b9255",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 100.30883741378784\n"
     ]
    }
   ],
   "source": [
    "# Random search since faster\n",
    "random_search = RandomizedSearchCV(rfc, hparams_grid, n_iter=10)\n",
    "\n",
    "# train and time it\n",
    "start = time.time()\n",
    "random_search.fit(Xtrain_encoded, Ytrain)\n",
    "end = time.time()\n",
    "time_grid_train = end - start\n",
    "print('Train time: {}'.format(time_grid_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e3fd9318-7d7f-4299-b518-61c7582c214e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1643360366633,
    "source_hash": "559b34df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8614908012363103\n",
      "Best params: {'n_estimators': 51, 'max_depth': 18}\n"
     ]
    }
   ],
   "source": [
    "# store best params\n",
    "r_best_m_d = random_search.best_params_['max_depth']\n",
    "r_best_n_e = random_search.best_params_['n_estimators']\n",
    "\n",
    "# print result\n",
    "print(\"Best Score: {}\".format(random_search.best_score_))\n",
    "print(\"Best params: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "baad69c8-7852-4ebd-b5fb-0a8ed9967e4f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1643360366675,
    "source_hash": "4c14d85d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAKE PIPELINE\n",
    "pipeline = make_pipeline(DictVectorizer(), # one-hot encode dicts\n",
    "                        StandardScaler(),\n",
    "                        SelectKBest(f_classif, k=100), # default f_classif, top 100 features\n",
    "                        # use best params found from above grid search\n",
    "                        RandomForestClassifier(max_depth=r_best_m_d, n_estimators=r_best_n_e, random_state=0, n_jobs=-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9a592fdc-69fc-4d0a-b596-de6af6e68df6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1643290218448,
    "source_hash": "6bf8436a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAKE PIPELINE\n",
    "pipeline = make_pipeline(DictVectorizer(), # one-hot encode dicts\n",
    "                        SelectKBest(f_classif, k=100), # default f_classif, top 100 features\n",
    "                        # use best params found from above grid search\n",
    "                        RandomForestClassifier(max_depth=r_best_m_d, n_estimators=r_best_n_e, random_state=0, n_jobs=-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1b92d899-d7b9-42e2-b7f3-0dd5ec00e4ea",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     97.9375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6197,
    "execution_start": 1643360366676,
    "source_hash": "62463063",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot center sparse matrices: pass `with_mean=False` instead. See docstring for motivation and alternatives.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c2a8d969a8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 871\u001b[0;31m                     \u001b[0;34m\"Cannot center sparse matrices: pass `with_mean=False` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0;34m\"instead. See docstring for motivation and alternatives.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot center sparse matrices: pass `with_mean=False` instead. See docstring for motivation and alternatives."
     ]
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(Xtrain_dicts, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fdf919a0-d11f-411c-bd15-d99e6794dcb1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a66236c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get accuracy on unseen test data\n",
    "accuracy_score(Ytest, pipeline.predict(Xtest_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ae3fcbab-4e1f-45c6-8d94-8a9ec78c2dc2",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 973,
    "execution_start": 1643290251566,
    "source_hash": "8023e62d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638290031324857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy on unseen test data\n",
    "accuracy_score(Ytest, pipeline.predict(Xtest_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c0d08905-2d4e-42e3-b57e-c4b36984b44a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Here we show the model's (rfc) features importance scores computed from the impurity-based feature importances (computed as the mean decreas in impurity). This is the most common method to compute feature importance and is therefor built into scikit-learns RFC model. Below are the top 10 scores giving best indication of earnings (y target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3eeae476-03e4-40b2-afdd-4c657d4409ab",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     520.0625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 110,
    "execution_start": 1643290275549,
    "source_hash": "629ce458",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-gain 0.1516155230915853\n",
      "marital-status=Married-civ-spouse 0.10718817182326537\n",
      "age 0.10698287365700311\n",
      "education-num 0.09045906901351733\n",
      "hours-per-week 0.07044134769451368\n",
      "occupation=Tech-support 0.06782105127450488\n",
      "capital-loss 0.0425116455988528\n",
      "marital-status=Never-married 0.03717284106381609\n",
      "native-country=United-States 0.02689571115649695\n",
      "occupation=Craft-repair 0.02074903708273899\n"
     ]
    }
   ],
   "source": [
    "# Get the names of each feature\n",
    "feature_names = pipeline.named_steps[\"dictvectorizer\"].get_feature_names_out()\n",
    "\n",
    "# Get the impurity-based feature importances\n",
    "rfc_feature_score = pipeline.named_steps[\"randomforestclassifier\"].feature_importances_\n",
    "\n",
    "# print top 10 result\n",
    "for s, f in sorted(zip(rfc_feature_score, feature_names), reverse=True)[:10]:\n",
    "    print(f, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3056b16a-ead6-4afa-8be6-a839b2d2686d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "##### Comments:\n",
    "\n",
    "The top features listed when using mutual_info_classif and f_classif were the below computed as the mean decrease in impurity. The importance score indicate that these features are most predictive of earnings:\n",
    "1. Capital Gain\n",
    "2. Maritial status (=Married), \n",
    "3. Age\n",
    "\n",
    "Capital gain can help describe the economy of a person and may be large or small as result of income. Naturally married 'Maritial status' can be a strong indicator of that you have a close partner/family that you prioritise and value highly. Generally we can argue that 'Age' results in higher salary growing with your role and career. However, as stated these do not indicate wheather the income was above or below the 50k. \n",
    "\n",
    "Other than the above tested scikitlearn's built in feature importance score one can use permutation based importance score described by Parr et al (2018). \n",
    "\n",
    "The perumation based importance score is the difference between the baseline accuracy and accuracy by permutin the column values. It is hevaier to compute but more reliable as less biased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "50cabc35-4c8e-402a-bbba-0004c3a884a1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "89b8993f-4978-4e1f-bddc-924bb3cb3604",
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
