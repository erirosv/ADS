{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data-set\n",
    "dat = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data to variables\n",
    "# preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = dat.load_data()\n",
    "\n",
    "# normalize for gray scale\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2527 - accuracy: 0.9235\n",
      "Epoch 2/40\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1033 - accuracy: 0.9673\n",
      "Epoch 3/40\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0728 - accuracy: 0.9774\n",
      "Epoch 4/40\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0562 - accuracy: 0.9822\n",
      "Epoch 5/40\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0446 - accuracy: 0.9854\n",
      "Epoch 6/40\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0343 - accuracy: 0.9886\n",
      "Epoch 7/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9901\n",
      "Epoch 8/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0262 - accuracy: 0.9915\n",
      "Epoch 9/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 10/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 11/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0180 - accuracy: 0.9938\n",
      "Epoch 12/40\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 13/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 14/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 15/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0160 - accuracy: 0.9947\n",
      "Epoch 16/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 0.9957\n",
      "Epoch 17/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 18/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 19/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 20/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 21/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 22/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "Epoch 23/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 24/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 25/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 26/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 27/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 28/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 29/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 30/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 31/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 32/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 33/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 34/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 35/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 36/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 37/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 38/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 39/40\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - accuracy: 0.9982\n",
      "Epoch 40/40\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0085 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x252acce7b50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-cd4bed5c4b99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\3.9.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1452\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1455\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\3.9.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\3.9.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\3.9.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\3.9.0\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1628\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1629\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
