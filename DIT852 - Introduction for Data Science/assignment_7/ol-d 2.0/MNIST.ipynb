{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28 numbers of 0-9\n",
    "(x_train, y_train), (x_test, y_test) = dat.load_data()\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1).reshape(x_train.shape[0], -1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1).reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 2.1805 - accuracy: 0.3927\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 1.8267 - accuracy: 0.7318\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 1.3380 - accuracy: 0.8012 0s - loss: 1\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model.add(tf.keras.layers.Dense(500, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(300, activation = tf.nn.relu)) \n",
    "#model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) \n",
    "#model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) \n",
    "#model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  \n",
    "\n",
    "# adam: good default optimizer | optimizer='adam',\n",
    "# loss: how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "# metrics: what to track, in this case it is 'accuracy'\n",
    "# TEST learning rate for 0.001 & 0.000001\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.0, nesterov=False, name='SGD'),\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.8253\n",
      "Loss: 1.09882652759552 | accuracy: 0.8252999782562256\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "val_acc = []\n",
    "# evaluate the out of sample data with model\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  \n",
    "\n",
    "#loss (error) accuracy\n",
    "print('Loss:',val_loss, '|', 'accuracy:', val_acc)  \n",
    "#print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.09882652759552 0.8252999782562256\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.losses.categorical_crossentropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
